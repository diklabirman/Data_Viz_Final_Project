{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, neighbors\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(r'C:\\Users\\Dikla\\Desktop\\fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          2       0       0       0       0       0       0       0       0   \n",
       "1          9       0       0       0       0       0       0       0       0   \n",
       "2          6       0       0       0       0       0       0       0       5   \n",
       "3          0       0       0       0       1       2       0       0       0   \n",
       "4          3       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995      9       0       0       0       0       0       0       0       0   \n",
       "59996      1       0       0       0       0       0       0       0       0   \n",
       "59997      8       0       0       0       0       0       0       0       0   \n",
       "59998      8       0       0       0       0       0       0       0       0   \n",
       "59999      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0        30        43   \n",
       "3           0  ...         3         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "59995       0  ...         0         0         0         0         0   \n",
       "59996       0  ...        73         0         0         0         0   \n",
       "59997       0  ...       160       162       163       135        94   \n",
       "59998       0  ...         0         0         0         0         0   \n",
       "59999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uploding test Data for later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(r'C:\\Users\\Dikla\\Desktop\\fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>182</td>\n",
       "      <td>199</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0         0       0       0       0       0       0       0       0       9   \n",
       "1         1       0       0       0       0       0       0       0       0   \n",
       "2         2       0       0       0       0       0       0      14      53   \n",
       "3         2       0       0       0       0       0       0       0       0   \n",
       "4         3       0       0       0       0       0       0       0       0   \n",
       "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9995      0       0       0       0       0       0       0       0       0   \n",
       "9996      6       0       0       0       0       0       0       0       0   \n",
       "9997      8       0       0       0       0       0       0       0       0   \n",
       "9998      8       0       1       3       0       0       0       0       0   \n",
       "9999      1       0       0       0       0       0       0       0     140   \n",
       "\n",
       "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0          8  ...       103        87        56         0         0         0   \n",
       "1          0  ...        34         0         0         0         0         0   \n",
       "2         99  ...         0         0         0         0        63        53   \n",
       "3          0  ...       137       126       140         0       133       224   \n",
       "4          0  ...         0         0         0         0         0         0   \n",
       "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "9995       0  ...        32        23        14        20         0         0   \n",
       "9996       0  ...         0         0         0         2        52        23   \n",
       "9997       0  ...       175       172       172       182       199       222   \n",
       "9998       0  ...         0         0         0         0         0         1   \n",
       "9999     119  ...       111        95        75        44         1         0   \n",
       "\n",
       "      pixel781  pixel782  pixel783  pixel784  \n",
       "0            0         0         0         0  \n",
       "1            0         0         0         0  \n",
       "2           31         0         0         0  \n",
       "3          222        56         0         0  \n",
       "4            0         0         0         0  \n",
       "...        ...       ...       ...       ...  \n",
       "9995         1         0         0         0  \n",
       "9996        28         0         0         0  \n",
       "9997        42         0         1         0  \n",
       "9998         0         0         0         0  \n",
       "9999         0         0         0         0  \n",
       "\n",
       "[10000 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot one image of the data to see how it looks for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d35d55bb20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = X0[30]\n",
    "image1 = image1.reshape(28,28)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d35d891130>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(image1, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59957 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          2       0       0       0       0       0       0       0       0   \n",
       "1          9       0       0       0       0       0       0       0       0   \n",
       "2          6       0       0       0       0       0       0       0       5   \n",
       "3          0       0       0       0       1       2       0       0       0   \n",
       "4          3       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995      9       0       0       0       0       0       0       0       0   \n",
       "59996      1       0       0       0       0       0       0       0       0   \n",
       "59997      8       0       0       0       0       0       0       0       0   \n",
       "59998      8       0       0       0       0       0       0       0       0   \n",
       "59999      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0        30        43   \n",
       "3           0  ...         3         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "59995       0  ...         0         0         0         0         0   \n",
       "59996       0  ...        73         0         0         0         0   \n",
       "59997       0  ...       160       162       163       135        94   \n",
       "59998       0  ...         0         0         0         0         0   \n",
       "59999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[59957 rows x 785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df0.drop_duplicates()\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for NaN\n",
    "#### All data is pixels so we dont expect for NaN but we'll check anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing of final test\n",
    "\n",
    "#### Drop label for the final test in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df_test.drop(['label'],axis = 1)\n",
    "y1 = df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = df0.drop(['label'],axis = 1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "#### Making the data ready for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(['label'],axis = 1)\n",
    "y = df1.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6545</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>200</td>\n",
       "      <td>208</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47965 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "6545        0       0       0       0       0       0       0       0       0   \n",
       "32849       0       0       0       0       0       0       0       1       2   \n",
       "5226        0       0       0       0       0       0       0       0       0   \n",
       "51886       0       0       0       0       0       0       1       0       0   \n",
       "52903       0       0       0       1       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "53310       0       0       0       0       0       0       0       0       0   \n",
       "5347        0       0       0       0       0       0       0       0       0   \n",
       "51254       0       0       0       0       0       0       0      10      10   \n",
       "870         0       0       0       0       0       0       0       0       0   \n",
       "59422       0       0       0       0       0       1       1       0       0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "6545         0  ...         0         0         0         0         0   \n",
       "32849        1  ...         0         0         0         0         0   \n",
       "5226         0  ...        34         0         0         0         0   \n",
       "51886        0  ...         0         0         0         0         1   \n",
       "52903       39  ...         0         3         0         0       175   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "53310        0  ...       103        56         0         4         0   \n",
       "5347         0  ...        41        33        34        12         0   \n",
       "51254       14  ...        25         0         9         8         0   \n",
       "870          0  ...         0         0         0         0       130   \n",
       "59422        0  ...         0         0         0         4        21   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "6545          0         0         0         0         0  \n",
       "32849         0         0         0         0         0  \n",
       "5226          0         0         0         0         0  \n",
       "51886         0         0         0         0         0  \n",
       "52903       200       208       150         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "53310         0         0         0         0         0  \n",
       "5347          1         0         0         0         0  \n",
       "51254         0         0         0         0         0  \n",
       "870         130        39         0         0         0  \n",
       "59422         1        29         0         0         0  \n",
       "\n",
       "[47965 rows x 784 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59957,), (47965,), (11992,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "### We need to normalized the data to be all values between 0-1 (normal distribution) so the model will not be \"confused\" by bigger numbers that have no significent effect on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train.values))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test.values))\n",
    "X_test_final = pd.DataFrame(scaler.transform(X1.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "### We will not do Dummy Classifier this time, the dummy should giva us about 10% accuracy because we have 10 different classes which mean 10 different clothing featuers that are mostly balanced. Usually we'll use Dummy classifier for comperation to our models , but all models have higher accuracy than 50% ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "### PCA- principal component analysis, is an algorithm that can explain wich precent of the data we can explain with the minimal amount of dimentions. PCA is a dimensionality reduction technique, which is in fact linear transformations applied on (usually) highly correlated multidimensional data. The input dimensions are transformed in a new coordinate system in which the produced dimensions contain, in decreasing order, the greatest variance related with unchanged landscape features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d= np.argmax(cumsum >= 0.95) \n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we can see that out of 800 dimentions, we can use only 254 for 95% of the data. which means we can wxplain 95% of the variance with 254 dimentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Explained Variance')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cumsum)\n",
    "plt.axhline(y=0.95 , linewidth = 0.5 , color = 'r');\n",
    "plt.axvline(x=d , linewidth = 0.5 , color = 'r');\n",
    "plt.xlabel(\"Dimantions\")\n",
    "plt.ylabel(\"Explained Variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.95)\n",
    "X_train_reduced = pd.DataFrame(pca.fit_transform(X_train))\n",
    "X_test_reduced = pd.DataFrame(pca.transform(X_test))\n",
    "X_test_reduced_final = pd.DataFrame(pca.transform(X_test_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before PCA\n",
    "### For best learning, lets do all models before PCA and all again after PCA . Then we can learn about it which one is better. usually, PCA will drop the accuracy slightly because we lower the dimentions so we can still explain 95% of the data. However, we take into consideraition that usually we'll get maximum 95% of the data, so it makes sence will loose a little bit of the accuracy while working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "### KNN is a model who works by nearset neighbors.The model 'looks' at the nearest neighbors calssification which will be the best parameter to decide which type-dog or cat is the most accurate for this new given picture. We can decied how many neighbors to check by the parameter = K which represents the scope of the search. also we can do some testing to see which K will gives us the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "knn_prediction = knn.predict(X_test)\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test,y_pred)\n",
    "print(knn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN gave us before PCA 85% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "### Random Forest model base on decision trees. this model has the ability to know which feature contains the most significant information. it \"runs\" on all features and tests which feature manages to divide the data to the most accurate division percentages. Random Forest model builds many decision trees for all features, and any new picture we need to calssify, will be applied on all these trees until it makes a decision which lable it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "RF_accuracy = accuracy_score(y_test,pred)\n",
    "print(RF_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest gave us before PCA 58% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting\n",
    "### voting model divided into hard voting and soft voting. as its name- this model makes a voting among all the models we have preformed and takes the highest score of them. the soft voting refer to the probabillity while the hard voting performs a simple vote between the models and takes the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators = [('knn',knn),(\"RF\",clf),('gaussian-bayes',gnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.fit(X_train,y_train)\n",
    "pred = voting.predict(X_test)\n",
    "voting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(voting_acuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting gave us before PCA 70% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting\n",
    "### Bagging and pasting - bootstrap aggregating , is a an algorithm which uses the same traning algorithm for evety predictor, but to train them on different random subsets of traning set. when sampling is performed with replacement, this method is called bagging. when sampling is performed without replacment it is called pasting.\n",
    "\n",
    "#### The Bagging classifier aoutomatically performs soft voting instead of hard voting if the base classifier cam estimate class probabilities.\n",
    "##### we'll try  Bagging first, and then we'll try again with pastin and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = True , n_jobs = -1)\n",
    "bag_clf.fit(X_train , y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "bagging_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(bagging_acuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf1 = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = False , n_jobs = -1)\n",
    "bag_clf1.fit(X_train , y_train)\n",
    "y_pred = bag_clf1.predict(X_test)\n",
    "pasting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(pasting_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Pasting gave us before PCA arount of 76% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "### To explain what XGBboost is we need first to understand what GradientBoost is. GradientBoosting soupports a subsample hyperparameter, which specifies the fraction of training instances to be used for training each tree. This trades a higher bias for a lower variance. it also speeds up traning considerably. after understanding what GradientBoost means, we can explaine what XGBoost means. XGBoost -Extreame Gradient Boosting is an optimized implementation of Gradient Boosting. it aims at being extreamly fast, scalable and portable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 1500,learning_rate = 0.05,use_label_encoder = False, eval_metric = \"merror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_train,y_train)\n",
    "pred = xgb_clf.predict(X_test)\n",
    "xgb_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(xgb_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost is the best model so far which gave us 90 % accuracy before PCA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "### AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier( DecisionTreeClassifier(max_depth = 1),n_estimators = 200,algorithm = \"SAMME.R\",learning_rate = 0.5)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "pred = ada_clf.predict(X_test)\n",
    "ada_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(ada_acuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['XGBoost', 'AdaBoost', 'RF', 'Voting', 'Pasting', 'Bagging', 'KNN']\n",
    "accuracy = [0.58,0.58,0.56,0.56,0.58,0.59,0.56]\n",
    "ax.bar(langs,accuracy)\n",
    "height = [0.58,0.58,0.56,0.56,0.58,0.59,0.56]\n",
    "bars = ('XGBoost', 'AdaBoost', 'RF', 'Voting', 'Pasting', 'Bagging', 'KNN')\n",
    "x_pos = np.arange(len(bars))\n",
    "\n",
    "# Create bars with different colors\n",
    "plt.bar(x_pos, height, color=['orange', 'pink', 'green', 'red', 'blue', 'yellow', 'purple'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_models = pd.DataFrame (np.array([['xgboost' ,xgb_acuracy], ['AdaBoost',ada_acuracy], ['RF' ,RF_accuracy],['voting' ,voting_acuracy], ['pasting',pasting_acuracy], ['bagging' ,bagging_acuracy], ['KNN' ,knn_accuracy]]),\n",
    "                   columns=['Model', 'Accuracy'])\n",
    "total_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see in this case, AdaBoost has the worst results for us with only 46% accuracy before PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After PCA\n",
    "### Now let's see the accuracy differences after PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnpca = KNeighborsClassifier()\n",
    "knnpca.fit(X_train_reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7635090060040026\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test,y_pred)\n",
    "print(knn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we have no change in the KNN accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6845396931287525\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_reduced,y_train)\n",
    "pred = clf.predict(X_test_reduced)\n",
    "RF_accuracy = accuracy_score(y_test,pred)\n",
    "print(RF_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Random Forest model, after PCA we actually got better results with 10% higher accuracy ! For this model dementionallity reduction works great, and we got 68% accuracy instead of 58% before PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "gnb = GaussianNB()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import VotingClassifier\n",
    "voting = VotingClassifier(estimators = [('knn',knn),(\"RF\",clf),('gaussian-bayes',gnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7635090060040026\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "voting.fit(X_train_reduced,y_train)\n",
    "pred = voting.predict(X_test_reduced)\n",
    "voting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(voting_acuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Voting model, after PCA we actually got better results with 8% higher accuracy ! For this model dementionallity reduction works great, and we got 78% accuracy instead of 70% before PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7385757171447632\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = True , n_jobs = -1)\n",
    "bag_clf.fit(X_train_reduced , y_train)\n",
    "y_pred = bag_clf.predict(X_test_reduced)\n",
    "bagging_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(bagging_acuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7396597731821214\n"
     ]
    }
   ],
   "source": [
    "bag_clf1 = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = False , n_jobs = -1)\n",
    "bag_clf1.fit(X_train_reduced , y_train)\n",
    "y_pred = bag_clf1.predict(X_test_reduced)\n",
    "pasting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(pasting_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Bagging and Pasting as expected the PCA actually droped 3% of the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost\n",
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 2000,learning_rate = 0.5,use_label_encoder = False, eval_metric = \"merror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_train_reduced,y_train)\n",
    "pred = xgb_clf.predict(X_test_reduced)\n",
    "xgb_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(xgb_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also for the XGBoost model the PCA droped 2% of the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7396597731821214\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier( DecisionTreeClassifier(max_depth = 1),n_estimators = 200,algorithm = \"SAMME.R\",learning_rate = 0.5)\n",
    "ada_clf.fit(X_train_reduced, y_train)\n",
    "pred = ada_clf.predict(X_test_reduced)\n",
    "ada_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(ada_acuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the AdaBoost model we actually got the best results ! we have 15% higher accuracy then before PCA. Here we can see big difference that dimentionallity reduction can make ! befor PCA we had 46% accuracy and now we have 61%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is a DataFrame of all accuracies by models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.7396597731821214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.7396597731821214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.6845396931287525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>voting</td>\n",
       "      <td>0.7635090060040026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pasting</td>\n",
       "      <td>0.7396597731821214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.7385757171447632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7635090060040026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model            Accuracy\n",
       "0   xgboost  0.7396597731821214\n",
       "1  AdaBoost  0.7396597731821214\n",
       "2        RF  0.6845396931287525\n",
       "3    voting  0.7635090060040026\n",
       "4   pasting  0.7396597731821214\n",
       "5   bagging  0.7385757171447632\n",
       "6       KNN  0.7635090060040026"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_models = pd.DataFrame (np.array([['xgboost' ,xgb_acuracy], ['AdaBoost',ada_acuracy], ['RF' ,RF_accuracy],['voting' ,voting_acuracy], ['pasting',pasting_acuracy], ['bagging' ,bagging_acuracy], ['KNN' ,knn_accuracy]]),\n",
    "                   columns=['Model', 'Accuracy'])\n",
    "total_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['XGBoost', 'AdaBoost', 'RF', 'Voting', 'Pasting', 'Bagging', 'KNN']\n",
    "accuracy = [0.88,0.73,0.68,0.76,0.73,0.73,0.76]\n",
    "ax.bar(langs,accuracy)\n",
    "height = [0.73,0.73,0.68,0.76,0.73,0.73,0.76]\n",
    "bars = ('XGBoost', 'AdaBoost', 'RF', 'Voting', 'Pasting', 'Bagging', 'KNN')\n",
    "x_pos = np.arange(len(bars))\n",
    "\n",
    "# Create bars with different colors\n",
    "plt.bar(x_pos, height, color=['orange', 'pink', 'green', 'red', 'blue', 'yellow', 'purple'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test\n",
    "### We got the best results on XGBoost model with 88% accuracy after PCA. Now we can run the final test we saved for last on the best model which gave us the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8922\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 2000,learning_rate = 0.04,use_label_encoder = False, eval_metric = \"merror\")\n",
    "xgb_clf.fit(X_train_reduced,y_train)\n",
    "pred = xgb_clf.predict(X_test_reduced_final)\n",
    "print(accuracy_score(y1,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## our final results is 89% accurcy !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "### PCA is an algorithm that can make us to get better results while we actually drop \"unnecessery\" dimentiond of the data we're working on. the meaning is we can still explain over 90% of the data well , but faster and more efficient by dimentionality reduction. As we can see, we tried many models befor and after PCA and each one of them reacted diffrently. Somtimes loosing 2% of the accuracy will be better for us if we made our model more efficient, so we'll need to calculate our \"risks\" and decide what is the best for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The END !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
