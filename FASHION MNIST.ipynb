{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, neighbors\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(r'C:\\Users\\Dikla\\Desktop\\fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          2       0       0       0       0       0       0       0       0   \n",
       "1          9       0       0       0       0       0       0       0       0   \n",
       "2          6       0       0       0       0       0       0       0       5   \n",
       "3          0       0       0       0       1       2       0       0       0   \n",
       "4          3       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995      9       0       0       0       0       0       0       0       0   \n",
       "59996      1       0       0       0       0       0       0       0       0   \n",
       "59997      8       0       0       0       0       0       0       0       0   \n",
       "59998      8       0       0       0       0       0       0       0       0   \n",
       "59999      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0        30        43   \n",
       "3           0  ...         3         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "59995       0  ...         0         0         0         0         0   \n",
       "59996       0  ...        73         0         0         0         0   \n",
       "59997       0  ...       160       162       163       135        94   \n",
       "59998       0  ...         0         0         0         0         0   \n",
       "59999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uploding test Data for later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(r'C:\\Users\\Dikla\\Desktop\\fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>182</td>\n",
       "      <td>199</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0         0       0       0       0       0       0       0       0       9   \n",
       "1         1       0       0       0       0       0       0       0       0   \n",
       "2         2       0       0       0       0       0       0      14      53   \n",
       "3         2       0       0       0       0       0       0       0       0   \n",
       "4         3       0       0       0       0       0       0       0       0   \n",
       "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9995      0       0       0       0       0       0       0       0       0   \n",
       "9996      6       0       0       0       0       0       0       0       0   \n",
       "9997      8       0       0       0       0       0       0       0       0   \n",
       "9998      8       0       1       3       0       0       0       0       0   \n",
       "9999      1       0       0       0       0       0       0       0     140   \n",
       "\n",
       "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0          8  ...       103        87        56         0         0         0   \n",
       "1          0  ...        34         0         0         0         0         0   \n",
       "2         99  ...         0         0         0         0        63        53   \n",
       "3          0  ...       137       126       140         0       133       224   \n",
       "4          0  ...         0         0         0         0         0         0   \n",
       "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "9995       0  ...        32        23        14        20         0         0   \n",
       "9996       0  ...         0         0         0         2        52        23   \n",
       "9997       0  ...       175       172       172       182       199       222   \n",
       "9998       0  ...         0         0         0         0         0         1   \n",
       "9999     119  ...       111        95        75        44         1         0   \n",
       "\n",
       "      pixel781  pixel782  pixel783  pixel784  \n",
       "0            0         0         0         0  \n",
       "1            0         0         0         0  \n",
       "2           31         0         0         0  \n",
       "3          222        56         0         0  \n",
       "4            0         0         0         0  \n",
       "...        ...       ...       ...       ...  \n",
       "9995         1         0         0         0  \n",
       "9996        28         0         0         0  \n",
       "9997        42         0         1         0  \n",
       "9998         0         0         0         0  \n",
       "9999         0         0         0         0  \n",
       "\n",
       "[10000 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot one image of the data to see how it looks for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d35d55bb20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = X0[30]\n",
    "image1 = image1.reshape(28,28)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d35d891130>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(image1, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59957 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          2       0       0       0       0       0       0       0       0   \n",
       "1          9       0       0       0       0       0       0       0       0   \n",
       "2          6       0       0       0       0       0       0       0       5   \n",
       "3          0       0       0       0       1       2       0       0       0   \n",
       "4          3       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995      9       0       0       0       0       0       0       0       0   \n",
       "59996      1       0       0       0       0       0       0       0       0   \n",
       "59997      8       0       0       0       0       0       0       0       0   \n",
       "59998      8       0       0       0       0       0       0       0       0   \n",
       "59999      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0        30        43   \n",
       "3           0  ...         3         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "59995       0  ...         0         0         0         0         0   \n",
       "59996       0  ...        73         0         0         0         0   \n",
       "59997       0  ...       160       162       163       135        94   \n",
       "59998       0  ...         0         0         0         0         0   \n",
       "59999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[59957 rows x 785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df0.drop_duplicates()\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for NaN\n",
    "#### All data is pixels so we dont expect for NaN but we'll check anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing of final test\n",
    "\n",
    "#### Drop label for the final test in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df_test.drop(['label'],axis = 1)\n",
    "y1 = df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = df0.drop(['label'],axis = 1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "#### Making the data ready for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(['label'],axis = 1)\n",
    "y = df1.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6545</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>200</td>\n",
       "      <td>208</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47965 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "6545        0       0       0       0       0       0       0       0       0   \n",
       "32849       0       0       0       0       0       0       0       1       2   \n",
       "5226        0       0       0       0       0       0       0       0       0   \n",
       "51886       0       0       0       0       0       0       1       0       0   \n",
       "52903       0       0       0       1       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "53310       0       0       0       0       0       0       0       0       0   \n",
       "5347        0       0       0       0       0       0       0       0       0   \n",
       "51254       0       0       0       0       0       0       0      10      10   \n",
       "870         0       0       0       0       0       0       0       0       0   \n",
       "59422       0       0       0       0       0       1       1       0       0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "6545         0  ...         0         0         0         0         0   \n",
       "32849        1  ...         0         0         0         0         0   \n",
       "5226         0  ...        34         0         0         0         0   \n",
       "51886        0  ...         0         0         0         0         1   \n",
       "52903       39  ...         0         3         0         0       175   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "53310        0  ...       103        56         0         4         0   \n",
       "5347         0  ...        41        33        34        12         0   \n",
       "51254       14  ...        25         0         9         8         0   \n",
       "870          0  ...         0         0         0         0       130   \n",
       "59422        0  ...         0         0         0         4        21   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "6545          0         0         0         0         0  \n",
       "32849         0         0         0         0         0  \n",
       "5226          0         0         0         0         0  \n",
       "51886         0         0         0         0         0  \n",
       "52903       200       208       150         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "53310         0         0         0         0         0  \n",
       "5347          1         0         0         0         0  \n",
       "51254         0         0         0         0         0  \n",
       "870         130        39         0         0         0  \n",
       "59422         1        29         0         0         0  \n",
       "\n",
       "[47965 rows x 784 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59957,), (47965,), (11992,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "### We need to normalized the data to be all values between 0-1 (normal distribution) so the model will not be \"confused\" by bigger numbers that have no significent effect on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train.values))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test.values))\n",
    "X_test_final = pd.DataFrame(scaler.transform(X1.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "### We will not do Dummy Classifier this time, the dummy should giva us about 10% accuracy because we have 10 different classes which mean 10 different clothing featuers that are mostly balanced. Usually we'll use Dummy classifier for comperation to our models , but all models have higher accuracy than 50% ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "### PCA- principal component analysis, is an algorithm that can explain wich precent of the data we can explain with the minimal amount of dimentions. PCA is a dimensionality reduction technique, which is in fact linear transformations applied on (usually) highly correlated multidimensional data. The input dimensions are transformed in a new coordinate system in which the produced dimensions contain, in decreasing order, the greatest variance related with unchanged landscape features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d= np.argmax(cumsum >= 0.95) \n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we can see that out of 800 dimentions, we can use only 254 for 95% of the data. which means we can wxplain 95% of the variance with 254 dimentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Explained Variance')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cumsum)\n",
    "plt.axhline(y=0.95 , linewidth = 0.5 , color = 'r');\n",
    "plt.axvline(x=d , linewidth = 0.5 , color = 'r');\n",
    "plt.xlabel(\"Dimantions\")\n",
    "plt.ylabel(\"Explained Variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.95)\n",
    "X_train_reduced = pd.DataFrame(pca.fit_transform(X_train))\n",
    "X_test_reduced = pd.DataFrame(pca.transform(X_test))\n",
    "X_test_reduced_final = pd.DataFrame(pca.transform(X_test_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before PCA\n",
    "### For best learning, lets do all models before PCA and all again after PCA . Then we can learn about it which one is better. usually, PCA will drop the accuracy slightly because we lower the dimentions so we can still explain 95% of the data. However, we take into consideraition that usually we'll get maximum 95% of the data, so it makes sence will loose a little bit of the accuracy while working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "### KNN is a model who works by nearset neighbors.The model 'looks' at the nearest neighbors calssification which will be the best parameter to decide which type-dog or cat is the most accurate for this new given picture. We can decied how many neighbors to check by the parameter = K which represents the scope of the search. also we can do some testing to see which K will gives us the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7396597731821214\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "knn_prediction = knn.predict(X_test)\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test,y_pred)\n",
    "print(knn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN gave us before PCA 85% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "### Random Forest model base on decision trees. this model has the ability to know which feature contains the most significant information. it \"runs\" on all features and tests which feature manages to divide the data to the most accurate division percentages. Random Forest model builds many decision trees for all features, and any new picture we need to calssify, will be applied on all these trees until it makes a decision which lable it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.587641761174116\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "RF_accuracy = accuracy_score(y_test,pred)\n",
    "print(RF_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest gave us before PCA 58% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting\n",
    "### voting model divided into hard voting and soft voting. as its name- this model makes a voting among all the models we have preformed and takes the highest score of them. the soft voting refer to the probabillity while the hard voting performs a simple vote between the models and takes the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators = [('knn',knn),(\"RF\",clf),('gaussian-bayes',gnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7396597731821214\n"
     ]
    }
   ],
   "source": [
    "voting.fit(X_train,y_train)\n",
    "pred = voting.predict(X_test)\n",
    "voting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(voting_acuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting gave us before PCA 70% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting\n",
    "### Bagging and pasting - bootstrap aggregating , is a an algorithm which uses the same traning algorithm for evety predictor, but to train them on different random subsets of traning set. when sampling is performed with replacement, this method is called bagging. when sampling is performed without replacment it is called pasting.\n",
    "\n",
    "#### The Bagging classifier aoutomatically performs soft voting instead of hard voting if the base classifier cam estimate class probabilities.\n",
    "##### we'll try  Bagging first, and then we'll try again with pastin and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76184122748499\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = True , n_jobs = -1)\n",
    "bag_clf.fit(X_train , y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "bagging_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(bagging_acuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7626751167444963\n"
     ]
    }
   ],
   "source": [
    "bag_clf1 = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = False , n_jobs = -1)\n",
    "bag_clf1.fit(X_train , y_train)\n",
    "y_pred = bag_clf1.predict(X_test)\n",
    "pasting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(pasting_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Pasting gave us before PCA arount of 76% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "### To explain what XGBboost is we need first to understand what GradientBoost is. GradientBoosting soupports a subsample hyperparameter, which specifies the fraction of training instances to be used for training each tree. This trades a higher bias for a lower variance. it also speeds up traning considerably. after understanding what GradientBoost means, we can explaine what XGBoost means. XGBoost -Extreame Gradient Boosting is an optimized implementation of Gradient Boosting. it aims at being extreamly fast, scalable and portable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 1500,learning_rate = 0.05,use_label_encoder = False, eval_metric = \"merror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7626751167444963\n"
     ]
    }
   ],
   "source": [
    "xgb_clf.fit(X_train,y_train)\n",
    "pred = xgb_clf.predict(X_test)\n",
    "xgb_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(xgb_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost is the best model so far which gave us 90 % accuracy before PCA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "### AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7626751167444963\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier( DecisionTreeClassifier(max_depth = 1),n_estimators = 200,algorithm = \"SAMME.R\",learning_rate = 0.5)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "pred = ada_clf.predict(X_test)\n",
    "ada_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(ada_acuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAE/CAYAAAAQZlkTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXZklEQVR4nO3df5RfdX3n8efLRCqKijZpbYGQ1GYPB11gdaRasdr1cBrUNrrrliC7QqumtMUWd+nZuGersN3TwnG1HhXNpjZL3UWx/g4Q5Vi3iBawCRCQIKkxtjDiLkFdFM0xBN/7x72BL8NM5pvkM5nvTJ6Pc+bk3s/9fO/3/cl35vu6n/u9cydVhSRJOnhPmO0CJEmaLwxVSZIaMVQlSWrEUJUkqRFDVZKkRgxVSZIaWThbT7xo0aJaunTpbD29JEkH5Oabb76/qhZPtm3WQnXp0qVs3rx5tp5ekqQDkuSfptrm6V9JkhoxVCVJasRQlSSpkaFCNcmKJNuSbE+yZoo+L0uyJcnWJF9sW6YkSaNv2guVkiwALgNOB8aBTUk2VNWdA32OBt4PrKiqu5P8zEwVLEnSqBpmpnoqsL2qdlTVbuBKYOWEPq8DPllVdwNU1X1ty5QkafQNE6rHAPcMrI/3bYP+GfCMJNcluTnJ61sVKEnSXDHM76lmkraJf4R1IfB84OXAkcCNSW6qqn94zI6S1cBqgCVLlux/tZIkjbBhZqrjwHED68cC907S53NV9cOquh+4Hjh54o6qal1VjVXV2OLFk96MQpKkOWuYUN0ELE+yLMkRwCpgw4Q+nwFekmRhkicDvwR8rW2pkiSNtmlP/1bVniTnA9cCC4D1VbU1yXn99rVV9bUknwNuB34CfLCq7pjJwiVJGjWpmvjx6KExNjZW3vtXkjTXJLm5qsYm2zZrN9SXpPllsms654LZmVjNV96mUJKkRgxVSZIaMVQlSWpk/nym+uE5+nnG6/bz84wvztGLu1466Wf6Ogxkjv5oztI1nJrjnKlKktSIoSpJUiOGqiRJjRiqkiQ1YqhKktSIoSpJUiOGqiRJjRiqkiQ1Mn9u/qB5IxfP0bsFAPX2/bhjgHdF0BxzcS6e7RIO2Nvr7YfkeZypSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNTJUqCZZkWRbku1J1kyy/WVJHkiypf96W/tSJUkabQun65BkAXAZcDowDmxKsqGq7pzQ9UtV9aoZqFGSpDlhmJnqqcD2qtpRVbuBK4GVM1uWJElzzzChegxwz8D6eN820YuS3Jbks0meM9mOkqxOsjnJ5p07dx5AuZIkja5hQjWTtNWE9VuA46vqZOC9wKcn21FVrauqsaoaW7x48f5VKknSiBsmVMeB4wbWjwXuHexQVd+vqgf75Y3AE5MsalalJElzwDChuglYnmRZkiOAVcCGwQ5JnpUk/fKp/X6/07pYSZJG2bRX/1bVniTnA9cCC4D1VbU1yXn99rXAa4HfTbIH2AWsqqqJp4glSZrXpg1VeOSU7sYJbWsHlt8HvK9taZIkzS3eUUmSpEYMVUmSGjFUJUlqxFCVJKkRQ1WSpEYMVUmSGjFUJUlqxFCVJKkRQ1WSpEYMVUmSGjFUJUlqxFCVJKkRQ1WSpEYMVUmSGjFUJUlqxFCVJKkRQ1WSpEYMVUmSGjFUJUlqxFCVJKkRQ1WSpEYMVUmSGjFUJUlqxFCVJKkRQ1WSpEYMVUmSGjFUJUlqxFCVJKkRQ1WSpEYMVUmSGjFUJUlqxFCVJKkRQ1WSpEYMVUmSGjFUJUlqxFCVJKkRQ1WSpEaGCtUkK5JsS7I9yZp99HtBkoeTvLZdiZIkzQ3ThmqSBcBlwBnAicBZSU6cot+lwLWti5QkaS4YZqZ6KrC9qnZU1W7gSmDlJP3eDHwCuK9hfZIkzRnDhOoxwD0D6+N92yOSHAO8BljbrjRJkuaWYUI1k7TVhPV3A/+xqh7e546S1Uk2J9m8c+fOYWuUJGlOWDhEn3HguIH1Y4F7J/QZA65MArAIeEWSPVX16cFOVbUOWAcwNjY2MZglSZrThgnVTcDyJMuAbwGrgNcNdqiqZXuXk1wOXD0xUCVJmu+mDdWq2pPkfLqrehcA66tqa5Lz+u1+jipJEsPNVKmqjcDGCW2ThmlVnXvwZUmSNPd4RyVJkhoxVCVJasRQlSSpEUNVkqRGDFVJkhoxVCVJasRQlSSpEUNVkqRGDFVJkhoxVCVJasRQlSSpEUNVkqRGDFVJkhoxVCVJasRQlSSpEUNVkqRGDFVJkhoxVCVJasRQlSSpEUNVkqRGDFVJkhoxVCVJasRQlSSpEUNVkqRGDFVJkhoxVCVJasRQlSSpEUNVkqRGDFVJkhoxVCVJasRQlSSpEUNVkqRGDFVJkhoxVCVJasRQlSSpEUNVkqRGDFVJkhoxVCVJamSoUE2yIsm2JNuTrJlk+8oktyfZkmRzktPalypJ0mhbOF2HJAuAy4DTgXFgU5INVXXnQLcvABuqqpKcBPw1cMJMFCxJ0qgaZqZ6KrC9qnZU1W7gSmDlYIeqerCqql99ClBIknSYGSZUjwHuGVgf79seI8lrktwFXAP89mQ7SrK6Pz28eefOnQdSryRJI2uYUM0kbY+biVbVp6rqBODVwJ9MtqOqWldVY1U1tnjx4v2rVJKkETdMqI4Dxw2sHwvcO1XnqroeeHaSRQdZmyRJc8owoboJWJ5kWZIjgFXAhsEOSX4xSfrl5wFHAN9pXawkSaNs2qt/q2pPkvOBa4EFwPqq2prkvH77WuBfA69P8hCwCzhz4MIlSZIOC9OGKkBVbQQ2TmhbO7B8KXBp29IkSZpbvKOSJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNDBWqSVYk2ZZke5I1k2w/O8nt/dcNSU5uX6okSaNt2lBNsgC4DDgDOBE4K8mJE7p9E3hpVZ0E/AmwrnWhkiSNumFmqqcC26tqR1XtBq4EVg52qKobqup7/epNwLFty5QkafQNE6rHAPcMrI/3bVN5A/DZgylKkqS5aOEQfTJJW03aMflVulA9bYrtq4HVAEuWLBmyREmS5oZhZqrjwHED68cC907slOQk4IPAyqr6zmQ7qqp1VTVWVWOLFy8+kHolSRpZw4TqJmB5kmVJjgBWARsGOyRZAnwS+HdV9Q/ty5QkafRNe/q3qvYkOR+4FlgArK+qrUnO67evBd4G/DTw/iQAe6pqbObKliRp9AzzmSpVtRHYOKFt7cDyG4E3ti1NkqS5xTsqSZLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjhqokSY0YqpIkNWKoSpLUiKEqSVIjQ4VqkhVJtiXZnmTNJNtPSHJjkh8nubB9mZIkjb6F03VIsgC4DDgdGAc2JdlQVXcOdPsu8AfAq2ekSkmS5oBhZqqnAturakdV7QauBFYOdqiq+6pqE/DQDNQoSdKcMEyoHgPcM7A+3rfttySrk2xOsnnnzp0HsgtJkkbWMKGaSdrqQJ6sqtZV1VhVjS1evPhAdiFJ0sgaJlTHgeMG1o8F7p2ZciRJmruGCdVNwPIky5IcAawCNsxsWZIkzT3TXv1bVXuSnA9cCywA1lfV1iTn9dvXJnkWsBl4GvCTJBcAJ1bV92ewdkmSRsq0oQpQVRuBjRPa1g4s/x+608KSJB22vKOSJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNGKqSJDViqEqS1IihKklSI4aqJEmNDBWqSVYk2ZZke5I1k2xPkvf0229P8rz2pUqSNNqmDdUkC4DLgDOAE4Gzkpw4odsZwPL+azXwgcZ1SpI08oaZqZ4KbK+qHVW1G7gSWDmhz0rgQ9W5CTg6yc81rlWSpJE2TKgeA9wzsD7et+1vH0mS5rWFQ/TJJG11AH1Ispru9DDAg0m2DfH8o2ARcP+M7Pnsyf7rZs3MjXN0zOgYc9HIvJ4zN86MzBhhBsc5WsOcye/bkRnojP5sXpSLWu7u+Kk2DBOq48BxA+vHAvceQB+qah2wbojnHClJNlfV2GzXMdMOh3EeDmMExznfHA7jnC9jHOb07yZgeZJlSY4AVgEbJvTZALy+vwr4hcADVfXtxrVKkjTSpp2pVtWeJOcD1wILgPVVtTXJef32tcBG4BXAduBHwG/NXMmSJI2mYU7/UlUb6YJzsG3twHIBv9+2tJEy505ZH6DDYZyHwxjBcc43h8M458UY0+WhJEk6WN6mUJKkRuZdqCY5Lsk3kzyzX39Gv358kuVJrk7yjSQ3J/nbJL/S9zs3yc4kW5JsTfLxJE9uWNcpSV7RaF+vSVJJTphi+3VJ9nkVXd9nWz/er/W/7tRM///58y33eQA1PNyP744kVyU5um9fmmRXv23v1xGzWetE/evzaxPaLkjy/in6/6cJ6zfMZH0tTHh9Pra/P2/96/i6gfWxJO9pX+n+GxjbbUluSfLLM/AcIzPe6SR5cGD5FUm+nmRJkouS/CjJz0zRt5K8c2D9wqTt78a0Nu9CtaruobtN4iV90yV05+r/L3ANsK6qnl1VzwfeDPzCwMM/WlWnVNVzgN3AmQ1LO4XuYq4WzgK+THcl9sE4u6pOAV4MXNo4WM4FZjVUgV396/lc4Ls89nP/b/Tb9n7tnqUap/IRHv/6rurbJ/OYUK2q5m/iM2Dw9dkNnLefj18KPBKqVbW5qv6gYX0HY+/YTgbeCvxZ6ycYsfEOJcnLgfcCK6rq7r75fuA/TPGQHwP/KsmiQ1FfC/MuVHt/DrwwyQXAacA7gbOBG6vqkV8Hqqo7quryiQ9OshB4CvC9fv34JF/o/1jAF5Ismab93/RH37club4Pq/8CnNkfvR5wWCc5ii4E30D/ppvkyCRX9nV8FDhyoP8HkmzuZ98XT7Hbo4AfAg/3jzkryVf7MVw6sK/HtSdZkOTyvu2rSd6S5LXAGHBFP94jJ3vSQ+xG5tZdvj4OvCrJT0E3K6M7SDl2ktfgEuDI/v/6ir7twf7fl/Wz3o8nuSvJFUl3W4N+xnBXki+n+4MYVx/6YT7iS8AvJvn1JF9JcmuSv0nys32tLx04q3BrkqfSHTC/pG97Sz/Wq/v+FyVZ3499R5JHwifJH/fj/nySjyS5cIbH9jQefS85qn+vuKV/HR+55etUdSV5Qf+zfWOSdyS5o28f1fFOKslLgL8AXllV3xjYtJ7uvfGZkzxsD92k6C2HoMQ2qmpefgG/RndXp9P79XcBf7iP/ucCO4EtdLPaLwEL+m1XAef0y78NfHqa9q8Cx/TLRw/s/30NxvVvgb/sl28Angf8e7pfdQI4ie4bcaxff2b/7wLgOuCkfv06YBtwO7AL+J2+/eeBu4HFdFeH/2/g1ftofz7w+YH6jh7Y/9gsfw88ODD2j9EdHUM3w9nVv9ZbgMtm+/t1ivqvAVb2y2vo3pAe9xoMjnWSsb8MeIDuhixPoDu4OA14Et2tRZf1/T4CXD1Lr89C4DPA7wLP4NELKN8IvLNfvgp4cb98VP+Ylw3WPLgOXNT/fPwU3Z16vgM8ke5gbwvdgedTga8DF87A2B7un+eu/v//+QNjfVq/vIju1xCzr7qAO4Bf7pcvAe4YtfEO8f/xEN3ZopMmtF8EXAi8Dbh44vcy8CDdQck/Ak/v+150qOvfn6/5OlOF7i/nfBt47mQbk3yqP9r/5EDzR6s7HfosumD8o779RcCH++X/SfemtK/2vwMuT/Imujf0ls6i+6MG9P+eBfwK8L8Aqup2uqDc6zeT3ALcCjyH7i8N7XV2VZ0ELAEuTHI88ALguqraWVV7gCv6/U/VvgP4hSTvTbIC+H7j8R6MI5NsoXuDeSbw+YFtg6d/R/XXwQZPAa+iu3PZZK/BdP6+qsar6id0b7BLgROAHVX1zYHnOtT2vj6b6Q4W/pIu/K9Nsvfn7zl9378D3tXPwI7uxz+da6rqx1V1P3Af8LN0P6OfqapdVfUDurCeCXtP/54ArAA+1J8hCPCnSW4H/obu7MmUdaW7DuCpVbX3M/IPT3yiAbM53uk8RBf6b5hi+3uAc5I8beKGqvo+8CFgTpzqnpehmuQU4HTghcBb0v3FnK10szoAquo1dLPHx51yqO4Q6SqmfsOa6veQqn/8ecB/prt145YkP31AA5mg38+/BD6Y5B/p3nTOpPtBnexey8vojuxe3ofnNXQzlMcWXbUTuAX4Jaa+Eeik7VX1PeBkupnp7wMf3J8xzbBd/UHS8cARzL3fpf408PJ0f5/4SOC2A9zPjweWH6abLY3CDV93DRzYvLm6z7XfS3dG558Dv0P//VpVl9DNXI8EbsoUF+lNMBLjrqob6WaPi+k+hlpMN3M9he6s2JP2Udf+1DsS453CT4DfBF6QCRfVAVTV/6M7YPi9KR7/brpAfsqMVdjIvAvV/mjwA8AF1X0Q/g7gv9G9YC9O8hsD3fd1teFpwN7z/jfw6IzhbLqLhKZsT/LsqvpKVb2N7kP444Af0J1+ORivpfsTe8dX1dKqOg74Jl0gnt0/93PpTgFDd9rkh8AD/WdTZ0y203RXXf6LfrxfAV6aZFG6v6V7FvDFqdrTXUDwhKr6BPDHPHrg0mK8TVTVA3RHuRcmeeJs1zOsqnqQ7mBlPd1McqrXBuCh/RzbXXRnGJb26y0vyjsYTwe+1S+fs7ex/5n6alVdSjezPYED+x77MvDrSZ6U7vqEVzaoeZ/6A4AFdGdMng7cV1UPJflVHr0x+6R19QetP0h3+1fY/4sTD/l4p1JVPwJeBZydZLIZ67voDqQed1Oiqvou8NdMPdMdGUPdUWmOeRNwd1XtPdX3froZ6al0L+i7kryb7gjxB8B/HXjsmUlOozvYGO8fB90b8vokf0T3uetvTdP+jiTL6Y4Sv0A3w7gbWNOf7vqzqvroAYztLB69qnmvT9AF4pH9KaUtwN8DVNVtSW6lm6XvoDuFNuiKJLvoPoe5vKpuBkjyVuBv+/o3VtVnpmpPcjLwP5LsPUB7a//v5cDafv8vqqpdBzDeZqrq1iS30b0pfWk2a9lPHwE+Cayqqm9P9drQXcxxe5Jbqurs6XZaVbuS/B7wuST303/PjICLgI8l+RZwE7Csb7+gD6GHgTuBz9LNfvb0r+vldB9x7FNVbUqyge5n8p/oAvqBxmOAR09tQ/danVNVD6e7kOyqJJt59DPX6ep6A/AXSX5Id5A1dL2HcLzD1vPd/mOi6/vvu8Ft9yf5FFNflPRO4PyZrvFgeUcl6TCV5KiqerA/u3MZ8PWq+vPZrmumDYz7ycD1wOqqumVU69rb3vdZA/xcVf3hwe53RgaheTlTlTScNyU5h+7z5luB/z7L9Rwq65KcSPdZ5l+NUMBMVdcr+zMUC+lmm+c22q9mgDNVSZIamXcXKkmSNFsMVUmSGjFUJUlqxFCVJKkRQ1WSpEYMVUmSGvn/dBj1Elx7PaMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['XGBoost', 'AdaBoost', 'RF', 'Voting', 'Pasting', 'Bagging', 'KNN']\n",
    "accuracy = [0.58,0.58,0.56,0.56,0.58,0.59,0.56]\n",
    "ax.bar(langs,accuracy)\n",
    "height = [0.58,0.58,0.56,0.56,0.58,0.59,0.56]\n",
    "bars = ('XGBoost', 'AdaBoost', 'RF', 'Voting', 'Pasting', 'Bagging', 'KNN')\n",
    "x_pos = np.arange(len(bars))\n",
    "\n",
    "# Create bars with different colors\n",
    "plt.bar(x_pos, height, color=['orange', 'pink', 'green', 'red', 'blue', 'yellow', 'purple'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.7626751167444963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.7626751167444963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.587641761174116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>voting</td>\n",
       "      <td>0.7396597731821214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pasting</td>\n",
       "      <td>0.7626751167444963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.76184122748499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7396597731821214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model            Accuracy\n",
       "0   xgboost  0.7626751167444963\n",
       "1  AdaBoost  0.7626751167444963\n",
       "2        RF   0.587641761174116\n",
       "3    voting  0.7396597731821214\n",
       "4   pasting  0.7626751167444963\n",
       "5   bagging    0.76184122748499\n",
       "6       KNN  0.7396597731821214"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_models = pd.DataFrame (np.array([['xgboost' ,xgb_acuracy], ['AdaBoost',ada_acuracy], ['RF' ,RF_accuracy],['voting' ,voting_acuracy], ['pasting',pasting_acuracy], ['bagging' ,bagging_acuracy], ['KNN' ,knn_accuracy]]),\n",
    "                   columns=['Model', 'Accuracy'])\n",
    "total_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see in this case, AdaBoost has the worst results for us with only 46% accuracy before PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After PCA\n",
    "### Now let's see the accuracy differences after PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnpca = KNeighborsClassifier()\n",
    "knnpca.fit(X_train_reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7635090060040026\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test,y_pred)\n",
    "print(knn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we have no change in the KNN accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6845396931287525\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_reduced,y_train)\n",
    "pred = clf.predict(X_test_reduced)\n",
    "RF_accuracy = accuracy_score(y_test,pred)\n",
    "print(RF_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Random Forest model, after PCA we actually got better results with 10% higher accuracy ! For this model dementionallity reduction works great, and we got 68% accuracy instead of 58% before PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "gnb = GaussianNB()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import VotingClassifier\n",
    "voting = VotingClassifier(estimators = [('knn',knn),(\"RF\",clf),('gaussian-bayes',gnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7635090060040026\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "voting.fit(X_train_reduced,y_train)\n",
    "pred = voting.predict(X_test_reduced)\n",
    "voting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(voting_acuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Voting model, after PCA we actually got better results with 8% higher accuracy ! For this model dementionallity reduction works great, and we got 78% accuracy instead of 70% before PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7385757171447632\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = True , n_jobs = -1)\n",
    "bag_clf.fit(X_train_reduced , y_train)\n",
    "y_pred = bag_clf.predict(X_test_reduced)\n",
    "bagging_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(bagging_acuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7396597731821214\n"
     ]
    }
   ],
   "source": [
    "bag_clf1 = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = False , n_jobs = -1)\n",
    "bag_clf1.fit(X_train_reduced , y_train)\n",
    "y_pred = bag_clf1.predict(X_test_reduced)\n",
    "pasting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(pasting_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Bagging and Pasting as expected the PCA actually droped 3% of the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost\n",
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 2000,learning_rate = 0.5,use_label_encoder = False, eval_metric = \"merror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7626751167444963\n"
     ]
    }
   ],
   "source": [
    "xgb_clf.fit(X_train_reduced,y_train)\n",
    "pred = xgb_clf.predict(X_test_reduced)\n",
    "xgb_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(xgb_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also for the XGBoost model the PCA droped 2% of the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7396597731821214\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier( DecisionTreeClassifier(max_depth = 1),n_estimators = 200,algorithm = \"SAMME.R\",learning_rate = 0.5)\n",
    "ada_clf.fit(X_train_reduced, y_train)\n",
    "pred = ada_clf.predict(X_test_reduced)\n",
    "ada_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(ada_acuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the AdaBoost model we actually got the best results ! we have 15% higher accuracy then before PCA. Here we can see big difference that dimentionallity reduction can make ! befor PCA we had 46% accuracy and now we have 61%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is a DataFrame of all accuracies by models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.7396597731821214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.7396597731821214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.6845396931287525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>voting</td>\n",
       "      <td>0.7635090060040026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pasting</td>\n",
       "      <td>0.7396597731821214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.7385757171447632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7635090060040026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model            Accuracy\n",
       "0   xgboost  0.7396597731821214\n",
       "1  AdaBoost  0.7396597731821214\n",
       "2        RF  0.6845396931287525\n",
       "3    voting  0.7635090060040026\n",
       "4   pasting  0.7396597731821214\n",
       "5   bagging  0.7385757171447632\n",
       "6       KNN  0.7635090060040026"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_models = pd.DataFrame (np.array([['xgboost' ,xgb_acuracy], ['AdaBoost',ada_acuracy], ['RF' ,RF_accuracy],['voting' ,voting_acuracy], ['pasting',pasting_acuracy], ['bagging' ,bagging_acuracy], ['KNN' ,knn_accuracy]]),\n",
    "                   columns=['Model', 'Accuracy'])\n",
    "total_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['XGBoost', 'AdaBoost', 'RF', 'Voting', 'Pasting', 'Bagging', 'KNN']\n",
    "accuracy = [0.88,0.73,0.68,0.76,0.73,0.73,0.76]\n",
    "ax.bar(langs,accuracy)\n",
    "height = [0.88,0.73,0.68,0.76,0.73,0.73,0.76]\n",
    "bars = ('XGBoost', 'AdaBoost', 'RF', 'Voting', 'Pasting', 'Bagging', 'KNN')\n",
    "x_pos = np.arange(len(bars))\n",
    "\n",
    "# Create bars with different colors\n",
    "plt.bar(x_pos, height, color=['orange', 'pink', 'green', 'red', 'blue', 'yellow', 'purple'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test\n",
    "### We got the best results on XGBoost model with 88% accuracy after PCA. Now we can run the final test we saved for last on the best model which gave us the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8922\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 2000,learning_rate = 0.04,use_label_encoder = False, eval_metric = \"merror\")\n",
    "xgb_clf.fit(X_train_reduced,y_train)\n",
    "pred = xgb_clf.predict(X_test_reduced_final)\n",
    "print(accuracy_score(y1,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## our final results is 89% accurcy !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "### PCA is an algorithm that can make us to get better results while we actually drop \"unnecessery\" dimentiond of the data we're working on. the meaning is we can still explain over 90% of the data well , but faster and more efficient by dimentionality reduction. As we can see, we tried many models befor and after PCA and each one of them reacted diffrently. Somtimes loosing 2% of the accuracy will be better for us if we made our model more efficient, so we'll need to calculate our \"risks\" and decide what is the best for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The END !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
