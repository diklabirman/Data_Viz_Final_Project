{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, neighbors\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(r'C:\\Users\\Dikla\\Desktop\\fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uploding test Data for later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(r'C:\\Users\\Dikla\\Desktop\\fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>182</td>\n",
       "      <td>199</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0         0       0       0       0       0       0       0       0       9   \n",
       "1         1       0       0       0       0       0       0       0       0   \n",
       "2         2       0       0       0       0       0       0      14      53   \n",
       "3         2       0       0       0       0       0       0       0       0   \n",
       "4         3       0       0       0       0       0       0       0       0   \n",
       "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9995      0       0       0       0       0       0       0       0       0   \n",
       "9996      6       0       0       0       0       0       0       0       0   \n",
       "9997      8       0       0       0       0       0       0       0       0   \n",
       "9998      8       0       1       3       0       0       0       0       0   \n",
       "9999      1       0       0       0       0       0       0       0     140   \n",
       "\n",
       "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0          8  ...       103        87        56         0         0         0   \n",
       "1          0  ...        34         0         0         0         0         0   \n",
       "2         99  ...         0         0         0         0        63        53   \n",
       "3          0  ...       137       126       140         0       133       224   \n",
       "4          0  ...         0         0         0         0         0         0   \n",
       "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "9995       0  ...        32        23        14        20         0         0   \n",
       "9996       0  ...         0         0         0         2        52        23   \n",
       "9997       0  ...       175       172       172       182       199       222   \n",
       "9998       0  ...         0         0         0         0         0         1   \n",
       "9999     119  ...       111        95        75        44         1         0   \n",
       "\n",
       "      pixel781  pixel782  pixel783  pixel784  \n",
       "0            0         0         0         0  \n",
       "1            0         0         0         0  \n",
       "2           31         0         0         0  \n",
       "3          222        56         0         0  \n",
       "4            0         0         0         0  \n",
       "...        ...       ...       ...       ...  \n",
       "9995         1         0         0         0  \n",
       "9996        28         0         0         0  \n",
       "9997        42         0         1         0  \n",
       "9998         0         0         0         0  \n",
       "9999         0         0         0         0  \n",
       "\n",
       "[10000 rows x 785 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot one image of the data to see how it looks for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d1dd87fe20>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = X0[30]\n",
    "image1 = image1.reshape(28,28)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d1dd916ac0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(image1, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59957 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          2       0       0       0       0       0       0       0       0   \n",
       "1          9       0       0       0       0       0       0       0       0   \n",
       "2          6       0       0       0       0       0       0       0       5   \n",
       "3          0       0       0       0       1       2       0       0       0   \n",
       "4          3       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995      9       0       0       0       0       0       0       0       0   \n",
       "59996      1       0       0       0       0       0       0       0       0   \n",
       "59997      8       0       0       0       0       0       0       0       0   \n",
       "59998      8       0       0       0       0       0       0       0       0   \n",
       "59999      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0        30        43   \n",
       "3           0  ...         3         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "59995       0  ...         0         0         0         0         0   \n",
       "59996       0  ...        73         0         0         0         0   \n",
       "59997       0  ...       160       162       163       135        94   \n",
       "59998       0  ...         0         0         0         0         0   \n",
       "59999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[59957 rows x 785 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df0.drop_duplicates()\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for NaN\n",
    "#### All data is pixels so we dont expect for NaN but we'll check anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing of final test\n",
    "\n",
    "#### Drop label for the final test in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df_test.drop(['label'],axis = 1)\n",
    "y1 = df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = df0.drop(['label'],axis = 1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "#### Making the data ready for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(['label'],axis = 1)\n",
    "y = df1.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6545</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>200</td>\n",
       "      <td>208</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47965 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "6545        0       0       0       0       0       0       0       0       0   \n",
       "32849       0       0       0       0       0       0       0       1       2   \n",
       "5226        0       0       0       0       0       0       0       0       0   \n",
       "51886       0       0       0       0       0       0       1       0       0   \n",
       "52903       0       0       0       1       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "53310       0       0       0       0       0       0       0       0       0   \n",
       "5347        0       0       0       0       0       0       0       0       0   \n",
       "51254       0       0       0       0       0       0       0      10      10   \n",
       "870         0       0       0       0       0       0       0       0       0   \n",
       "59422       0       0       0       0       0       1       1       0       0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "6545         0  ...         0         0         0         0         0   \n",
       "32849        1  ...         0         0         0         0         0   \n",
       "5226         0  ...        34         0         0         0         0   \n",
       "51886        0  ...         0         0         0         0         1   \n",
       "52903       39  ...         0         3         0         0       175   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "53310        0  ...       103        56         0         4         0   \n",
       "5347         0  ...        41        33        34        12         0   \n",
       "51254       14  ...        25         0         9         8         0   \n",
       "870          0  ...         0         0         0         0       130   \n",
       "59422        0  ...         0         0         0         4        21   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "6545          0         0         0         0         0  \n",
       "32849         0         0         0         0         0  \n",
       "5226          0         0         0         0         0  \n",
       "51886         0         0         0         0         0  \n",
       "52903       200       208       150         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "53310         0         0         0         0         0  \n",
       "5347          1         0         0         0         0  \n",
       "51254         0         0         0         0         0  \n",
       "870         130        39         0         0         0  \n",
       "59422         1        29         0         0         0  \n",
       "\n",
       "[47965 rows x 784 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59957,), (47965,), (11992,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "### We need to normalized the data to be all values between 0-1 (normal distribution) so the model will not be \"confused\" by bigger numbers that have no significent effect on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train.values))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test.values))\n",
    "X_test_final = pd.DataFrame(scaler.transform(X1.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "### We will not do Dummy Classifier this time, the dummy should giva us about 10% accuracy because we have 10 different classes which mean 10 different clothing featuers that are mostly balanced. Usually we'll use Dummy classifier for comperation to our models , but all models have higher accuracy than 50% ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "### PCA- principal component analysis, is an algorithm that can explain wich precent of the data we can explain with the minimal amount of dimentions. PCA is a dimensionality reduction technique, which is in fact linear transformations applied on (usually) highly correlated multidimensional data. The input dimensions are transformed in a new coordinate system in which the produced dimensions contain, in decreasing order, the greatest variance related with unchanged landscape features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d= np.argmax(cumsum >= 0.95) \n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we can see that out of 800 dimentions, we can use only 254 for 95% of the data. which means we can wxplain 95% of the variance with 254 dimentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Explained Variance')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cumsum)\n",
    "plt.axhline(y=0.95 , linewidth = 0.5 , color = 'r');\n",
    "plt.axvline(x=d , linewidth = 0.5 , color = 'r');\n",
    "plt.xlabel(\"Dimantions\")\n",
    "plt.ylabel(\"Explained Variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.95)\n",
    "X_train_reduced = pd.DataFrame(pca.fit_transform(X_train))\n",
    "X_test_reduced = pd.DataFrame(pca.transform(X_test))\n",
    "X_test_reduced_final = pd.DataFrame(pca.transform(X_test_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before PCA\n",
    "### For best learning, lets do all models before PCA and all again after PCA . Then we can learn about it which one is better. usually, PCA will drop the accuracy slightly because we lower the dimentions so we can still explain 95% of the data. However, we take into consideraition that usually we'll get maximum 95% of the data, so it makes sence will loose a little bit of the accuracy while working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "### KNN is a model who works by nearset neighbors.The model 'looks' at the nearest neighbors calssification which will be the best parameter to decide which type-dog or cat is the most accurate for this new given picture. We can decied how many neighbors to check by the parameter = K which represents the scope of the search. also we can do some testing to see which K will gives us the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "knn_prediction = knn.predict(X_test)\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN gave us before PCA 85% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "### Random Forest model base on decision trees. this model has the ability to know which feature contains the most significant information. it \"runs\" on all features and tests which feature manages to divide the data to the most accurate division percentages. Random Forest model builds many decision trees for all features, and any new picture we need to calssify, will be applied on all these trees until it makes a decision which lable it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.587641761174116\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest gave us before PCA 58% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting\n",
    "### voting model divided into hard voting and soft voting. as its name- this model makes a voting among all the models we have preformed and takes the highest score of them. the soft voting refer to the probabillity while the hard voting performs a simple vote between the models and takes the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators = [('knn',knn),(\"RF\",clf),('gaussian-bayes',gnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7023015343562375\n"
     ]
    }
   ],
   "source": [
    "voting.fit(X_train,y_train)\n",
    "pred = voting.predict(X_test)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting gave us before PCA 70% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting\n",
    "### Bagging and pasting - bootstrap aggregating , is a an algorithm which uses the same traning algorithm for evety predictor, but to train them on different random subsets of traning set. when sampling is performed with replacement, this method is called bagging. when sampling is performed without replacment it is called pasting.\n",
    "\n",
    "#### The Bagging classifier aoutomatically performs soft voting instead of hard voting if the base classifier cam estimate class probabilities.\n",
    "##### we'll try  Bagging first, and then we'll try again with pastin and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620913942628419\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = True , n_jobs = -1)\n",
    "bag_clf.fit(X_train , y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7631754503002002\n"
     ]
    }
   ],
   "source": [
    "bag_clf1 = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = False , n_jobs = -1)\n",
    "bag_clf1.fit(X_train , y_train)\n",
    "y_pred = bag_clf1.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Pasting gave us before PCA arount of 76% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "### To explain what XGBboost is we need first to understand what GradientBoost is. GradientBoosting soupports a subsample hyperparameter, which specifies the fraction of training instances to be used for training each tree. This trades a higher bias for a lower variance. it also speeds up traning considerably. after understanding what GradientBoost means, we can explaine what XGBoost means. XGBoost -Extreame Gradient Boosting is an optimized implementation of Gradient Boosting. it aims at being extreamly fast, scalable and portable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 1500,learning_rate = 0.05,use_label_encoder = False, eval_metric = \"merror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9083555703802535\n"
     ]
    }
   ],
   "source": [
    "xgb_clf.fit(X_train,y_train)\n",
    "pred = xgb_clf.predict(X_test)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost is the best model so far which gave us 90 % accuracy before PCA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "### AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46080720480320214\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier( DecisionTreeClassifier(max_depth = 1),n_estimators = 200,algorithm = \"SAMME.R\",learning_rate = 0.5)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "pred = ada_clf.predict(X_test)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see in this case, AdaBoost has the worst results for us with only 46% accuracy before PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After PCA\n",
    "### Now let's see the accuracy differences after PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnpca = KNeighborsClassifier()\n",
    "knnpca.fit(X_train_reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8535690460306872\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test,y_pred)\n",
    "print(knn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we have no change in the KNN accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6845396931287525\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_reduced,y_train)\n",
    "pred = clf.predict(X_test_reduced)\n",
    "RF_accuracy = accuracy_score(y_test,pred)\n",
    "print(RF_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Random Forest model, after PCA we actually got better results with 10% higher accuracy ! For this model dementionallity reduction works great, and we got 68% accuracy instead of 58% before PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "gnb = GaussianNB()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import VotingClassifier\n",
    "voting = VotingClassifier(estimators = [('knn',knn),(\"RF\",clf),('gaussian-bayes',gnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7800200133422281\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "voting.fit(X_train_reduced,y_train)\n",
    "pred = voting.predict(X_test_reduced)\n",
    "voting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(voring_acuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Voting model, after PCA we actually got better results with 8% higher accuracy ! For this model dementionallity reduction works great, and we got 78% accuracy instead of 70% before PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7342394929953302\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = True , n_jobs = -1)\n",
    "bag_clf.fit(X_train_reduced , y_train)\n",
    "y_pred = bag_clf.predict(X_test_reduced)\n",
    "bagging_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(bagging_acuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7336557705136758\n"
     ]
    }
   ],
   "source": [
    "bag_clf1 = BaggingClassifier(DecisionTreeClassifier() , n_estimators = 500, max_samples = 100, bootstrap = False , n_jobs = -1)\n",
    "bag_clf1.fit(X_train_reduced , y_train)\n",
    "y_pred = bag_clf1.predict(X_test_reduced)\n",
    "pasting_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(pasting_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Bagging and Pasting as expected the PCA actually droped 3% of the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost\n",
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 2000,learning_rate = 0.04,use_label_encoder = False, eval_metric = \"merror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889342895263509\n"
     ]
    }
   ],
   "source": [
    "xgb_clf.fit(X_train_reduced,y_train)\n",
    "pred = xgb_clf.predict(X_test_reduced)\n",
    "xgb_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(xgb_acuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also for the XGBoost model the PCA droped 2% of the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61974649766511\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier( DecisionTreeClassifier(max_depth = 1),n_estimators = 200,algorithm = \"SAMME.R\",learning_rate = 0.5)\n",
    "ada_clf.fit(X_train_reduced, y_train)\n",
    "pred = ada_clf.predict(X_test_reduced)\n",
    "ada_acuracy = accuracy_score(y_test,y_pred)\n",
    "print(ada_acuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the AdaBoost model we actually got the best results ! we have 15% higher accuracy then before PCA. Here we can see big difference that dimentionallity reduction can make ! befor PCA we had 46% accuracy and now we have 61%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is a DataFrame of all accuracies by models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_models = pd.DataFrame (np.array([['xgboost' ,xgb_acuracy], ['AdaBoost',ada_acuracy], ['RF' ,RF_acuracy],['voting' ,voting_acuracy], ['pasting',pasting_acuracy], ['bagging' ,bagging_acuracy], ['KNN' ,knn_accuracy]]),\n",
    "                   columns=['Model', 'Accuracy'])\n",
    "total_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "graph = sns.countplot(x='Model', data=total_models) #df + label \n",
    "graph.set_title(\"Total accuracy \", fontsize=20) #title\n",
    "graph.set_xlabel(\"models\", fontsize=15) # label\n",
    "graph.set_ylabel(\"accuracy\", fontsize=15) #label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test\n",
    "### We got the best results on XGBoost model with 88% accuracy after PCA. Now we can run the final test we saved for last on the best model which gave us the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 2000,learning_rate = 0.04,use_label_encoder = False, eval_metric = \"merror\")\n",
    "xgb_clf.fit(X_train_reduced,y_train)\n",
    "pred = xgb_clf.predict(X_test_reduced_final)\n",
    "print(accuracy_score(y1,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "### PCA is an algorithm that can make us to get better results while we actually drop \"unnecessery\" dimentiond of the data we're working on. the meaning is we can still explain over 90% of the data well , but faster and more efficient by dimentionality reduction. As we can see, we tried many models befor and after PCA and each one of them reacted diffrently. Somtimes loosing 2% of the accuracy will be better for us if we made our model more efficient, so we'll need to calculate our \"risks\" and decide what is the best for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The END !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
